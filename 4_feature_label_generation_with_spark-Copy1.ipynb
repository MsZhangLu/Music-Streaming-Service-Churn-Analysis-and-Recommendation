{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data into Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This statement allow to display plot without asking to\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: string, event: string, song_id: string, date: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv('../data/event_ds.csv',header=True).cache()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new or overwrite original field with withColumn\n",
    "df = df.withColumn('date',F.col('date').cast('date'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple count rows\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select operation, count distinct rows\n",
    "df.select('uid').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by aggregation\n",
    "df.groupBy('event').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by aggregation, more general (count, min, max, mean), multiple at once\n",
    "df.groupBy('event').agg(\n",
    "    F.count(F.col('uid')).alias('count'),\n",
    "    F.max(F.col('uid')).alias('max_uid')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter operation\n",
    "# group by aggregation\n",
    "# order by operation\n",
    "df.filter((F.col('date')>='2017-04-01') & (F.col('date')<='2017-04-05')) \\\n",
    "                    .groupBy('date','event').count() \\\n",
    "                    .orderBy('date','event').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_count = df.groupBy('date').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(date_count['date'],date_count['count'])\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "label_window_size = 14\n",
    "label_window_end_date = parser.parse('2017-05-12').date()\n",
    "label_window_start_date = label_window_end_date - datetime.timedelta(label_window_size - 1)\n",
    "print('label window:',label_window_start_date,'~',label_window_end_date,'days:',label_window_size)\n",
    "\n",
    "feature_window_size = 30\n",
    "feature_window_end_date = label_window_start_date - datetime.timedelta(1)\n",
    "feature_window_start_date = feature_window_end_date  - datetime.timedelta(feature_window_size - 1)\n",
    "print('feature window:',feature_window_start_date,'~',feature_window_end_date,'days:',feature_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the uid we will model\n",
    "df_model_uid = df.filter((F.col('date')>=feature_window_start_date) & (F.col('date')<=feature_window_end_date))\\\n",
    "                    .select('uid').distinct()\n",
    "# active in label window (active label=0)\n",
    "df_active_uid_in_label_window = df.filter((F.col('date')>=label_window_start_date) & (F.col('date')<=label_window_end_date))\\\n",
    "                            .select('uid').distinct().withColumn('label',F.lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare label data (churn label=1; active label=0)\n",
    "df_label = df_model_uid.join(df_active_uid_in_label_window,on=['uid'],how='left')\n",
    "df_label = df_label.fillna(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_data in feature_window\n",
    "df_feature_window = df.filter((F.col('date')>=feature_window_start_date) & (F.col('date')<=feature_window_end_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to generate frequency features\n",
    "def frequency_feature_generation(df,event,time_window,snapshot_date):\n",
    "    \"\"\"\n",
    "    generate frequency features for one event type and one time window\n",
    "    \"\"\"\n",
    "    df_feature = df.filter(F.col('event')==event)\\\n",
    "            .filter((F.col('date')>=snapshot_date-datetime.timedelta(time_window-1)) & (F.col('date')<=snapshot_date))\\\n",
    "            .groupBy('uid').agg(F.count(F.col('uid')).alias('freq_'+event+'_last_'+str(time_window)))\n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate one feature\n",
    "event = 'S'\n",
    "time_window = 3\n",
    "snapshot_date = feature_window_end_date\n",
    "df_feature = frequency_feature_generation(df_feature_window,event,time_window,snapshot_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate frequency features for all event_list, time_window_list\n",
    "event_list = ['P','D','S']\n",
    "time_window_list = [1,3,7,14,30]\n",
    "df_feature_list = []\n",
    "for event in event_list:\n",
    "    for time_window in time_window_list:\n",
    "        df_feature_list.append(frequency_feature_generation(df_feature_window,event,time_window,snapshot_date))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### method 2: too many dfs to join? do it another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to generate frequency features for a list of time windows\n",
    "# using when().otherwise(), and list comprehension trick!\n",
    "def frequency_feature_generation_time_windows(df,event,time_window_list,snapshot_date):\n",
    "    \"\"\"\n",
    "    generate frequency features for one event type and a list of time windows\n",
    "    \"\"\"\n",
    "    df_feature = df \\\n",
    "        .filter(F.col('event')==event) \\\n",
    "        .groupBy('uid') \\\n",
    "        .agg(*[F.sum(F.when((F.col('date')>=snapshot_date-datetime.timedelta(time_window-1)) & (F.col('date')<=snapshot_date),1).otherwise(0)).alias('freq_'+event+'_last_'+str(time_window)) \\\n",
    "                for time_window in time_window_list]\n",
    "            )# *[] opens list and make them comma separated\n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate one event type, all time windows \n",
    "event = 'S'\n",
    "time_window_list = [1,3,7,14,30]\n",
    "snapshot_date = feature_window_end_date\n",
    "df_feature = frequency_feature_generation_time_windows(df_feature_window,event,time_window_list,snapshot_date)\n",
    "df_feature.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate frequency features for all event_list, time_window_list\n",
    "event_list = ['P','D','S']\n",
    "time_window_list = [1,3,7,14,30]\n",
    "df_feature_list = []\n",
    "for event in event_list:\n",
    "    df_feature_list.append(frequency_feature_generation_time_windows(df_feature_window,event,time_window_list,snapshot_date))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defined as days from last event\n",
    "# can generate one feature for each type of event\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play = spark.read.csv('../data/play_ds.csv',header=True)\n",
    "df_play.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_feature_window = df_play.filter((F.col('date')>=feature_window_start_date) & (F.col('date')<=feature_window_end_date))\n",
    "df_profile_tmp = df_play_feature_window.select('uid','device').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile_tmp.groupBy('device').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if one user has two devices\n",
    "df_profile_tmp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile_tmp.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile_tmp = df_profile_tmp.withColumn('device_type',F.when(F.col('device')=='ip',1).otherwise(2))\n",
    "df_profile_tmp.groupBy('device_type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile = df_label.select('uid').join(df_profile_tmp.select('uid','device_type'),on='uid',how='left')\n",
    "df_profile.groupBy('device_type').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total play time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you generate total song play time features (using play_ds data) for different time window\n",
    "# using play data (need to clean play time first, play time may be negative in data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancier frequency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you generate counts of songs play 80% of their song length (using play_ds data) for different time window\n",
    "# using play data (need to clean play time and song length first, play time may be negative in data, song length may be zeros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_feature_data(df_master,df_feature_list):\n",
    "    for df_feature in df_feature_list:\n",
    "        df_master = df_master.join(df_feature,on='uid',how='left')\n",
    "        #df_master.persist() # uncomment if number of joins is too many\n",
    "    return df_master\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all behavior features\n",
    "df_model_final = join_feature_data(df_label,df_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all profile features\n",
    "df_model_final = join_feature_data(df_model_final,[df_profile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_final.fillna(0).toPandas().to_csv('../data/df_model_final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
